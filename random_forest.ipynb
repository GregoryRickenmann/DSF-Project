{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basics:**\n",
    "Decision trees iterate over each feature and its possible split points and select the split point that minimizes the loss function. Then, split the previously identified regions until maximum tree depth or minimum observations per area are reached (stopping criterion)\n",
    "\n",
    "To prevent overfitting, use cost complexity pruning (a complexity parameter alpha that punished the model for being too complex).\n",
    "\n",
    "Using bagging (resampling) to decrease variance (trees are high variance, low bias). Calculate bagging error over out of bag error (OOB) as some data is not part of the model. \n",
    "\n",
    "Random Forests create multiple decision trees using different subsets of the data and random subsets of features, introducing variation to each tree. The model aggregates their predictions by averaging the result of each tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import and define the features and target\n",
    "\n",
    "#target = df[\"Gewicht in Tonnen\"]\n",
    "#feature1 = df[\"\"]\n",
    "#\n",
    "\n",
    "#for time-series random forest you need to lag features and target to preserve temporal order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "def create_lagged_features(df, target_column, lags):\n",
    "    lagged_df = pd.DataFrame()\n",
    "    for lag in range(1, lags + 1):\n",
    "        for col in df.columns:\n",
    "            lagged_df[f'{col}_lag_{lag}'] = df[col].shift(lag)\n",
    "    lagged_df[target_column] = df[target_column]  # Keep the target variable\n",
    "    return lagged_df\n",
    "\n",
    "# Generate lagged features\n",
    "#afterwards test for optimal lags\n",
    "lags = 3  # Use 3 lag steps\n",
    "lagged_data = create_lagged_features(data, 'target', lags)\n",
    "\n",
    "# Drop NaN values caused by lagging\n",
    "lagged_data = lagged_data.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Define the number of splits for rolling cross-validation\n",
    "n_splits = 5\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "# Initialize lists to store mean squared errors\n",
    "mse_train_list = []\n",
    "mse_test_list = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Create and train the decision tree regressor\n",
    "    tree_regressor = DecisionTreeRegressor(random_state=42)\n",
    "    tree_regressor.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred = tree_regressor.predict(X_train)\n",
    "    y_test_pred = tree_regressor.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    \n",
    "    mse_train_list.append(mse_train)\n",
    "    mse_test_list.append(mse_test)\n",
    "\n",
    "# Calculate the average mean squared error for train and test sets\n",
    "avg_mse_train = np.mean(mse_train_list)\n",
    "avg_mse_test = np.mean(mse_test_list)\n",
    "\n",
    "print(f'Average Mean Squared Error for the decision tree (train): {avg_mse_train}')\n",
    "print(f'Average Mean Squared Error for the decision tree (test): {avg_mse_test}')\n",
    "\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(tree_regressor, filled=True, feature_names=X_train.columns, rounded=True)\n",
    "plt.show()\n",
    "\n",
    "# Initialize lists to store mean squared errors for random forest\n",
    "mse_train_rf_list = []\n",
    "mse_test_rf_list = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Create and train the random forest regressor\n",
    "    rf_regressor = RandomForestRegressor(n_estimators=B, random_state=42)\n",
    "    rf_regressor.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred_rf = rf_regressor.predict(X_train)\n",
    "    y_test_pred_rf = rf_regressor.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mse_train_rf = mean_squared_error(y_train, y_train_pred_rf)\n",
    "    mse_test_rf = mean_squared_error(y_test, y_test_pred_rf)\n",
    "    \n",
    "    mse_train_rf_list.append(mse_train_rf)\n",
    "    mse_test_rf_list.append(mse_test_rf)\n",
    "\n",
    "# Calculate the average mean squared error for train and test sets\n",
    "avg_mse_train_rf = np.mean(mse_train_rf_list)\n",
    "avg_mse_test_rf = np.mean(mse_test_rf_list)\n",
    "\n",
    "print(f'Average Mean Squared Error for the random forest (train): {avg_mse_train_rf}')\n",
    "print(f'Average Mean Squared Error for the random forest (test): {avg_mse_test_rf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
